# ğŸ“Š GUÃA DE OBSERVABILIDAD EP3

## Documento de Monitoreo y AnÃ¡lisis

**Proyecto:** Agente Inteligente PastelerÃ­a 1000 Sabores  
**EvaluaciÃ³n:** EP3 - Observabilidad y Monitoreo  
**Fecha:** 2025-01-26  

---

## 1. INTRODUCCIÃ“N

La observabilidad es la capacidad de entender el estado interno de un sistema mediante sus outputs externos (logs, mÃ©tricas, eventos). EP3 implementa un sistema completo de observabilidad con:

- **MÃ©tricas:** Mediciones numÃ©ricas del comportamiento
- **Logs:** Eventos detallados del sistema
- **Trazabilidad:** Seguimiento de requests end-to-end
- **Dashboards:** VisualizaciÃ³n en tiempo real
- **Alertas:** Notificaciones de anomalÃ­as

---

## 2. ARQUITECTURA DE OBSERVABILIDAD

### 2.1 Capas de RecolecciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     AplicaciÃ³n (app_agent.py)       â”‚
â”‚  - Ejecuta queries del usuario      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚          â”‚        â”‚
    v             v          v        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚MÃ©tricasâ”‚  â”‚  Logs  â”‚ â”‚ Security â”‚ â”‚ AnomalÃ­asâ”‚
â”‚        â”‚  â”‚        â”‚ â”‚          â”‚ â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚             â”‚          â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Storage         â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚metrics.json     â”‚
    â”‚logs/*.log       â”‚
    â”‚analysis.json    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Dashboard.py     â”‚
    â”‚ VisualizaciÃ³n    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Flujo de Datos

```
User Query
    â†“
[SecurityValidator]
    â”œâ”€ validate_input()
    â”œâ”€ sanitize_input()
    â””â”€ check_rate_limit()
    â†“
[PasteleriaAgentExecutor]
    â”œâ”€ Herramientas
    â”œâ”€ Memory
    â””â”€ [ObservabilityMetrics]
        â”œâ”€ record_query()
        â”œâ”€ record_response()
        â”œâ”€ measure_resources()
        â””â”€ save_metrics()
    â†“
[LogsAnalyzer] (async)
    â”œâ”€ parse_logs()
    â”œâ”€ get_errors_summary()
    â”œâ”€ get_bottlenecks()
    â””â”€ generate_report()
    â†“
[AnomalyDetector]
    â”œâ”€ detect_spike()
    â”œâ”€ detect_drift()
    â””â”€ classify_severity()
    â†“
[ImprovementRecommender]
    â”œâ”€ check_precision()
    â”œâ”€ check_latency()
    â”œâ”€ check_errors()
    â””â”€ generate_recommendations()
    â†“
[Dashboard.py]
    â”œâ”€ Visualiza mÃ©tricas
    â”œâ”€ Muestra anomalÃ­as
    â”œâ”€ Sugiere mejoras
    â””â”€ Reporta seguridad
```

---

## 3. COMPONENTES PRINCIPALES

### 3.1 ObservabilityMetrics (IE1, IE2)

**UbicaciÃ³n:** `src/monitoring/metrics.py`

**Responsabilidades:**
- Medir precisiÃ³n de respuestas
- Calcular latencia y recursos
- Registrar errores
- Persistir datos

**MÃ©todos Principales:**

```python
# IE1: PrecisiÃ³n y Consistencia
calculate_precision()       # % respuestas correctas
calculate_consistency()     # Coherencia entre respuestas
calculate_error_frequency() # Errores por 100 queries

# IE2: Latencia y Recursos
measure_resources()    # Latencia, memoria, CPU, tokens
get_latency_stats()   # Min, max, average
get_resource_stats()  # Memory, CPU, tokens

# Almacenamiento
export_metrics()      # Exporta a JSON
```

**Uso:**

```python
from src.monitoring.metrics import ObservabilityMetrics

metrics = ObservabilityMetrics()

# Registrar query
query_id = metrics.record_query("Â¿CuÃ¡nto cuesta la torta?")

# Ejecutar...
execution_time = 1.2  # segundos

# Registrar resultado
metrics.record_response(query_id, "La torta cuesta $15.000", is_correct=True)
metrics.measure_resources(execution_time, tokens_prompt=50, tokens_response=120)

# Ver estadÃ­sticas
summary = metrics.get_summary()
print(f"PrecisiÃ³n: {summary['precision']}%")
print(f"Errores: {summary['error_frequency']}%")
```

### 3.2 LogsAnalyzer (IE3, IE4)

**UbicaciÃ³n:** `src/monitoring/logs_analyzer.py`

**Responsabilidades:**
- Parsear logs del sistema
- Identificar errores y patrones
- Detectar anomalÃ­as
- Generar reportes

**MÃ©todos Principales:**

```python
# IE3: AnÃ¡lisis de Logs
get_errors_summary()      # Resumen de errores
get_bottlenecks()         # Operaciones lentas
get_tool_usage_analysis() # DesempeÃ±o de herramientas

# IE4: Patrones y AnomalÃ­as
identify_patterns()       # Patrones de uso
detect_anomalies()        # AnomalÃ­as detectadas
```

**Uso:**

```python
from src.monitoring.logs_analyzer import LogsAnalyzer

analyzer = LogsAnalyzer(log_dir="./logs")

# Obtener resumen de errores
errors = analyzer.get_errors_summary()
print(f"Total errores: {errors['total_errors']}")
print(f"Tasa de error: {errors['error_frequency']}%")

# Identificar cuellos de botella
bottlenecks = analyzer.get_bottlenecks(threshold_ms=5000)
for bn in bottlenecks:
    print(f"OperaciÃ³n lenta: {bn['message']} ({bn['execution_time_ms']}ms)")

# Generar reporte completo
report_path = analyzer.generate_report()
print(f"Reporte guardado en: {report_path}")
```

### 3.3 AnomalyDetector (IE4, IE7)

**UbicaciÃ³n:** `src/monitoring/anomaly_detector.py`

**Responsabilidades:**
- Detectar spikes en mÃ©tricas
- Identificar degradaciÃ³n (drift)
- Generar recomendaciones

**MÃ©todos Principales:**

```python
# DetecciÃ³n
detect_spike(metric_name)     # Picos inusuales
detect_drift(metric_name)     # DegradaciÃ³n gradual
get_anomaly_summary()         # Resumen de anomalÃ­as

# Recomendaciones (IE7)
generate_recommendations()    # Mejoras priorizadas
```

**Uso:**

```python
from src.monitoring.anomaly_detector import AnomalyDetector, ImprovementRecommender
import json

detector = AnomalyDetector()

# Simular mediciones
detector.add_measurement("latency", 1200)  # 1.2s
detector.add_measurement("latency", 1150)
detector.add_measurement("latency", 5500)  # Spike!

# Calcular baseline
detector.calculate_baseline("latency")

# Detectar spikes
spikes = detector.detect_spike("latency", threshold_std=3.0)
for spike in spikes:
    print(f"Spike detectado: {spike['value']}ms (desviaciÃ³n: {spike['deviation']}Ïƒ)")

# Generar recomendaciones
with open("metrics/metrics.json") as f:
    metrics = json.load(f)

recommender = ImprovementRecommender(metrics, {}, [])
recommendations = recommender.generate_recommendations()

for rec in recommendations:
    print(f"[{rec['severity']}] {rec['title']}")
    print(f"  Acciones: {rec['actions']}")
```

### 3.4 SecurityValidator (IE6)

**UbicaciÃ³n:** `src/security/validators.py`

**Responsabilidades:**
- Validar entrada del usuario
- Sanitizar datos
- Rate limiting
- Auditar incidentes

**MÃ©todos Principales:**

```python
validate_input(query)         # Valida entrada
sanitize_input(query)         # Sanitiza peligrosos
check_rate_limit()           # Verifica lÃ­mite
mask_sensitive_data()        # Enmascara privados
get_security_report()        # Reporte de incidentes
```

**Uso:**

```python
from src.security.validators import SecurityValidator

security = SecurityValidator(max_requests_per_minute=60)

# Validar entrada
query = "Â¿CuÃ¡nto cuesta la torta?"
is_valid, message = security.validate_input(query)

if is_valid:
    # Sanitizar
    safe_query = security.sanitize_input(query)
    
    # Procesar...
    response = "La torta cuesta $15.000"
    
    # Sanitizar output
    safe_response = security.sanitize_response(response)
    
    # Registrar acceso
    security.log_data_access("user123", "product_query", "READ")
else:
    print(f"Entrada rechazada: {message}")

# Ver reporte de seguridad
report = security.get_security_report()
print(f"Incidentes crÃ­ticos: {report['critical_incidents']}")
```

---

## 4. DASHBOARD DE OBSERVABILIDAD

### 4.1 Ejecutar Dashboard

```bash
streamlit run dashboard.py
```

### 4.2 Tabs del Dashboard

| Tab | Indicador | Contenido |
|-----|-----------|----------|
| ğŸ“ˆ MÃ©tricas | IE1, IE2 | PrecisiÃ³n, latencia, recursos |
| ğŸ”§ Logs | IE3 | Errores, herramientas, patrones |
| âš ï¸ AnomalÃ­as | IE4 | Spikes, drift, recomendaciones |
| ğŸ›¡ï¸ Seguridad | IE6 | Incidentes, features, histÃ³rico |
| ğŸ’¡ Mejoras | IE7 | Recomendaciones priorizadas |

### 4.3 MÃ©tricas Mostradas

**Tab MÃ©tricas:**
- PrecisiÃ³n (IE1): % respuestas correctas
- Error Frequency (IE1): Errores por 100 queries
- Latencia Promedio (IE2): Tiempo promedio de respuesta
- Memoria (IE2): GB usados
- CPU (IE2): % utilizaciÃ³n
- GrÃ¡ficos de tendencia

**Tab Logs:**
- Total de errores
- Tipos de errores mÃ¡s frecuentes
- Cuellos de botella detectados
- Uso por herramienta
- DistribuciÃ³n de tipos de queries

**Tab AnomalÃ­as:**
- Spikes detectados
- Drift en mÃ©tricas
- Patrones anormales
- Recomendaciones automÃ¡ticas

**Tab Seguridad:**
- Status: ğŸŸ¢ SEGURO / ğŸ”´ EN RIESGO
- Rate limit actual
- Capas de validaciÃ³n activas
- GrÃ¡fico de incidentes histÃ³ricos

**Tab Mejoras:**
- Recomendaciones con severidad
- DescripciÃ³n de problema
- Acciones sugeridas
- Impacto estimado
- Esfuerzo requerido

---

## 5. EJEMPLOS DE USO

### 5.1 IntegraciÃ³n en app_agent.py

```python
import streamlit as st
from src.monitoring.metrics import ObservabilityMetrics
from src.security.validators import SecurityValidator

# Inicializar
metrics = ObservabilityMetrics()
security = SecurityValidator()

# Interfaz
st.title("Agente Inteligente")

user_query = st.text_input("Â¿En quÃ© te puedo ayudar?")

if user_query:
    # Validar seguridad
    is_valid, msg = security.validate_input(user_query)
    if not is_valid:
        st.error(f"âŒ {msg}")
        st.stop()
    
    # Registrar mÃ©trica
    query_id = metrics.record_query(user_query, query_type="general")
    
    # Ejecutar (pseudo-cÃ³digo)
    import time
    start = time.time()
    response = agent.execute(user_query)
    exec_time = time.time() - start
    
    # Registrar resultado
    metrics.record_response(query_id, response, is_correct=True)
    metrics.measure_resources(exec_time, tokens_prompt=100, tokens_response=50)
    
    # Mostrar
    st.write(response)
    
    # Mostrar mÃ©tricas
    with st.expander("ğŸ“Š MÃ©tricas"):
        summary = metrics.get_summary()
        col1, col2, col3 = st.columns(3)
        col1.metric("PrecisiÃ³n", f"{summary['precision']:.1f}%")
        col2.metric("Errores", f"{summary['error_frequency']:.1f}%")
        col3.metric("Latencia", f"{exec_time:.2f}s")
```

### 5.2 AnÃ¡lisis Manual de Logs

```bash
# 1. Generar reporte
python -c "
from src.monitoring.logs_analyzer import LogsAnalyzer
analyzer = LogsAnalyzer('./logs')
report_path = analyzer.generate_report()
print(f'Reporte guardado en: {report_path}')
"

# 2. Ver reporte
cat ./logs/analysis_report.json | jq '.'

# 3. Ver solo errores
cat ./logs/analysis_report.json | jq '.errors_summary'
```

### 5.3 DetecciÃ³n de AnomalÃ­as

```python
from src.monitoring.anomaly_detector import AnomalyDetector
import json

# Cargar mÃ©tricas histÃ³ricas
with open("metrics/metrics.json") as f:
    metrics_data = json.load(f)

# Crear detector
detector = AnomalyDetector()

# Simular series de tiempo (en producciÃ³n, serÃ­an datos reales)
latencies = [1200, 1150, 1180, 1200, 5200, 1250, 1200, 1150]
for lat in latencies:
    detector.add_measurement("latency", lat)

# Detectar anomalÃ­as
summary = detector.get_anomaly_summary()

print("=== RESUMEN DE ANOMALÃAS ===")
print(f"MÃ©tricas monitoreadas: {summary['metrics_monitored']}")
print(f"Spikes detectados: {len(summary['spikes'])}")
print(f"Drifts detectados: {len(summary['drifts'])}")
print(f"\nProblemas crÃ­ticos:")
for issue in summary['critical_issues']:
    print(f"  - {issue}")
```

---

## 6. INTERPRETACIÃ“N DE MÃ‰TRICAS

### 6.1 PrecisiÃ³n (IE1)

```
< 70%  : ğŸ”´ CRÃTICO - Revisar algoritmo
70-80% : ğŸŸ  BAJO   - Mejorar prompts
80-90% : ğŸŸ¡ MEDIO  - Aceptable
> 90%  : ğŸŸ¢ ALTO   - Excelente
```

### 6.2 Latencia (IE2)

```
< 500ms   : ğŸŸ¢ EXCELENTE - Muy rÃ¡pido
500ms-2s  : ğŸŸ¢ BUENO     - Aceptable
2s-5s     : ğŸŸ¡ LENTO     - Revisar optimizaciones
> 5s      : ğŸ”´ CRÃTICO   - Optimizar urgente
```

### 6.3 Error Frequency (IE1)

```
< 1%      : ğŸŸ¢ EXCELENTE
1-5%      : ğŸŸ¡ ACEPTABLE
5-10%     : ğŸŸ  MEDIOCRE  - Revisar
> 10%     : ğŸ”´ CRÃTICO   - Actuar inmediatamente
```

---

## 7. TROUBLESHOOTING

### Problema: No se guardan mÃ©tricas

```python
# Verificar que directorio existe
import os
os.makedirs("./metrics", exist_ok=True)
os.makedirs("./logs", exist_ok=True)

# Verificar permisos de escritura
import pathlib
pathlib.Path("./metrics/test.txt").write_text("test")
```

### Problema: Dashboard no muestra datos

```bash
# Verificar que archivos existen
ls -la ./metrics/
ls -la ./logs/

# Regenerar anÃ¡lisis
python -c "
from src.monitoring.logs_analyzer import LogsAnalyzer
analyzer = LogsAnalyzer()
analyzer.generate_report()
"
```

---

## 8. MEJORES PRÃCTICAS

âœ… Monitorear regularmente el dashboard  
âœ… Revisar recomendaciones semanalmente  
âœ… Investigar anomalÃ­as dentro de 24h  
âœ… Implementar mejoras de alto impacto primero  
âœ… Documentar cambios y sus efectos  
âœ… Mantener histÃ³rico de mÃ©tricas  

---

**GuÃ­a v1.0 | 2025-01-26**
